{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "Lab7_Random_Forest.ipynb",
      "authorship_tag": "ABX9TyNQWW80mdnCUUlIMT/9B79H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anandchauhan21/Machine_Learning/blob/main/Labs/Lab7_Random_Forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üß™ Lab 7: Random Forest ‚Äî Disease Likelihood Prediction\n",
        "\n",
        "## üéØ Objective\n",
        "To implement a **Random Forest Classifier** to predict the likelihood of a disease\n",
        "using patient demographic, lifestyle, and clinical history data.\n",
        "\n",
        "---\n",
        "\n",
        "## üìö Learning Outcomes\n",
        "By the end of this lab, you will be able to:\n",
        "- Build and train a Random Forest classifier.\n",
        "- Evaluate its performance using classification metrics.\n",
        "- Visualize feature importance.\n",
        "- Tune hyperparameters for optimal results.\n",
        "- Predict disease likelihood for new patient data.\n"
      ],
      "metadata": {
        "id": "TUBMIw3Ibo1b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üß† Concept Recap ‚Äî Random Forest Classifier\n",
        "\n",
        "## üå≥ What is a Random Forest?\n",
        "- **Random Forest** is an **ensemble learning method** that combines multiple **Decision Trees**.\n",
        "- Each tree learns from a random subset of data and features, which helps reduce **overfitting**.\n",
        "- The final prediction is made by **majority voting** (for classification) or **averaging** (for regression).\n",
        "\n",
        "---\n",
        "\n",
        "## ‚öôÔ∏è How Random Forest Works\n",
        "1. **Bootstrap Sampling** ‚Äî Each tree trains on a random subset of the dataset.\n",
        "2. **Feature Randomness** ‚Äî At each split, a random subset of features is considered.\n",
        "3. **Aggregation** ‚Äî Predictions from all trees are combined to form the final output.\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Why Random Forest for Health Data?\n",
        "- Handles **nonlinear** relationships well.\n",
        "- Works with **imbalanced or noisy data**.\n",
        "- Gives **feature importance** (helps interpret which parameters matter most).\n",
        "- Suitable for **tabular clinical data**.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚öñÔ∏è Common Evaluation Metrics\n",
        "| Metric | Meaning | Ideal Value |\n",
        "|---------|----------|-------------|\n",
        "| Accuracy | Overall correctness | High |\n",
        "| Precision | TP / (TP + FP) | High |\n",
        "| Recall (Sensitivity) | TP / (TP + FN) | High |\n",
        "| F1-score | Balance of Precision & Recall | High |\n",
        "| ROC-AUC | Probability model ranks positive higher than negative | Close to 1 |\n",
        "\n",
        "---\n",
        "\n",
        "## üß© Example Use Case\n",
        "Predict if a patient has a **high likelihood of hypertension or diabetes**\n",
        "based on features like **Age, BMI, BP, Cholesterol, Glucose, Smoking, Family History**, etc.\n"
      ],
      "metadata": {
        "id": "ETMHPcqacCDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, roc_auc_score, roc_curve,\n",
        "    accuracy_score, precision_score, recall_score, f1_score\n",
        ")\n",
        "from sklearn.utils import resample\n",
        "import joblib\n",
        "import warnings\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "np.random.seed(42)\n"
      ],
      "metadata": {
        "id": "lDdRjr4fcATN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Synthetic patient dataset\n",
        "def create_synthetic_patient_history(n=1000):\n",
        "    np.random.seed(42)\n",
        "    age = np.random.randint(18, 85, n)\n",
        "    bmi = np.round(np.random.normal(27, 4, n), 1)\n",
        "    systolic = np.round(110 + 0.5*age + 0.4*bmi + np.random.normal(0, 10, n), 1)\n",
        "    diastolic = np.round(70 + 0.2*age + 0.2*bmi + np.random.normal(0, 6, n), 1)\n",
        "    cholesterol = np.round(np.random.normal(200, 30, n), 1)\n",
        "    glucose = np.round(np.random.normal(100, 20, n), 1)\n",
        "    smoking = np.random.binomial(1, 0.25, n)\n",
        "    family_history = np.random.binomial(1, 0.2, n)\n",
        "    physical_activity = np.random.randint(0, 5, n)\n",
        "\n",
        "    risk_score = (0.03*age + 0.06*bmi + 0.02*systolic + 0.015*cholesterol +\n",
        "                  0.5*smoking + 0.8*family_history - 0.2*physical_activity)\n",
        "    prob = 1 / (1 + np.exp(-0.08*(risk_score - 12)))\n",
        "    disease = np.random.binomial(1, prob)\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'Age': age,\n",
        "        'BMI': bmi,\n",
        "        'SystolicBP': systolic,\n",
        "        'DiastolicBP': diastolic,\n",
        "        'Cholesterol': cholesterol,\n",
        "        'Glucose': glucose,\n",
        "        'Smoking': smoking,\n",
        "        'FamilyHistory': family_history,\n",
        "        'PhysicalActivity': physical_activity,\n",
        "        'Disease': disease\n",
        "    })\n",
        "    return df\n",
        "\n",
        "df = create_synthetic_patient_history(1200)\n",
        "print(\"‚úÖ Dataset created. Shape:\", df.shape)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "o5Kgu1d3cFh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['Disease'].value_counts(normalize=True).round(3))\n",
        "print(\"\\nSummary Statistics:\")\n",
        "display(df.describe().T)\n",
        "\n",
        "# Correlation heatmap\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "plt.title(\"Feature Correlation Heatmap\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "u2phpUhvcHCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['Age','BMI','SystolicBP','DiastolicBP','Cholesterol','Glucose',\n",
        "            'Smoking','FamilyHistory','PhysicalActivity']\n",
        "X = df[features]\n",
        "y = df['Disease']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Balance classes (if needed)\n",
        "train = pd.concat([X_train, y_train], axis=1)\n",
        "minority = train[train['Disease']==1]\n",
        "majority = train[train['Disease']==0]\n",
        "print(\"Before resampling:\", train['Disease'].value_counts().to_dict())\n",
        "\n",
        "if len(minority) < 0.7 * len(majority):\n",
        "    minority_upsampled = resample(minority, replace=True, n_samples=len(majority), random_state=42)\n",
        "    train = pd.concat([majority, minority_upsampled])\n",
        "    X_train, y_train = train[features], train['Disease']\n",
        "    print(\"After upsampling:\", y_train.value_counts().to_dict())\n",
        "\n",
        "# Scaling (optional for RF, but good practice)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "-Lg5YJrQcIGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = rf.predict(X_test_scaled)\n",
        "y_proba = rf.predict_proba(X_test_scaled)[:,1]\n",
        "\n",
        "# Evaluate\n",
        "print(\"Accuracy:\", round(accuracy_score(y_test, y_pred), 3))\n",
        "print(\"Precision:\", round(precision_score(y_test, y_pred), 3))\n",
        "print(\"Recall:\", round(recall_score(y_test, y_pred), 3))\n",
        "print(\"F1 Score:\", round(f1_score(y_test, y_pred), 3))\n",
        "print(\"ROC AUC:\", round(roc_auc_score(y_test, y_proba), 3))\n"
      ],
      "metadata": {
        "id": "fqjmajJQcJiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\"); plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc_score(y_test, y_proba):.3f}\")\n",
        "plt.plot([0,1],[0,1],'--', color='gray')\n",
        "plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9klg9kQycKtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importances = pd.Series(rf.feature_importances_, index=features).sort_values(ascending=True)\n",
        "plt.figure(figsize=(7,5))\n",
        "importances.plot(kind='barh', color='teal')\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.show()\n",
        "\n",
        "display(importances.sort_values(ascending=False))\n"
      ],
      "metadata": {
        "id": "uRHB3orKcL6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import randint as sp_randint\n",
        "\n",
        "param_dist = {\n",
        "    'n_estimators': sp_randint(50, 300),\n",
        "    'max_depth': sp_randint(3, 20),\n",
        "    'min_samples_split': sp_randint(2, 10),\n",
        "    'min_samples_leaf': sp_randint(1, 6),\n",
        "    'max_features': ['sqrt', 'log2', 0.5, None]\n",
        "}\n",
        "\n",
        "rsearch = RandomizedSearchCV(\n",
        "    RandomForestClassifier(random_state=42),\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=20, cv=3, scoring='roc_auc', n_jobs=-1, random_state=42\n",
        ")\n",
        "rsearch.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Best parameters:\", rsearch.best_params_)\n",
        "best_rf = rsearch.best_estimator_\n",
        "print(\"Best CV ROC AUC:\", round(rsearch.best_score_, 3))\n"
      ],
      "metadata": {
        "id": "fneaEG8mcNOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "joblib.dump(best_rf, \"rf_disease_model.joblib\")\n",
        "joblib.dump(scaler, \"scaler.joblib\")\n",
        "print(\"‚úÖ Model saved successfully.\")\n",
        "\n",
        "# Predict for a new patient\n",
        "new_patient = pd.DataFrame([{\n",
        "    'Age': 52, 'BMI': 31.5, 'SystolicBP': 145, 'DiastolicBP': 90,\n",
        "    'Cholesterol': 250, 'Glucose': 120, 'Smoking': 1,\n",
        "    'FamilyHistory': 1, 'PhysicalActivity': 1\n",
        "}])\n",
        "\n",
        "scaler = joblib.load(\"scaler.joblib\")\n",
        "model = joblib.load(\"rf_disease_model.joblib\")\n",
        "X_new = scaler.transform(new_patient)\n",
        "prob = model.predict_proba(X_new)[0,1]\n",
        "pred = model.predict(X_new)[0]\n",
        "\n",
        "print(f\"Predicted Probability: {prob:.3f}\")\n",
        "print(f\"Disease Likelihood: {'High (1)' if pred==1 else 'Low (0)'}\")\n"
      ],
      "metadata": {
        "id": "lxzR_BQpcPVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üß© Recap ‚Äî Random Forest for Disease Prediction\n",
        "\n",
        "### What we did\n",
        "‚úÖ Generated or loaded patient history dataset  \n",
        "‚úÖ Performed feature scaling and balanced the classes  \n",
        "‚úÖ Trained a **Random Forest** model  \n",
        "‚úÖ Evaluated using Accuracy, F1, and ROC-AUC  \n",
        "‚úÖ Visualized feature importance and confusion matrix  \n",
        "‚úÖ Tuned model hyperparameters  \n",
        "‚úÖ Predicted disease likelihood for new patients  \n",
        "\n",
        "---\n",
        "\n",
        "### Key Insights\n",
        "- Random Forest can model complex, nonlinear health patterns.  \n",
        "- Important predictors might include **Age**, **BMI**, **Blood Pressure**, **Cholesterol**, etc.  \n",
        "- Ensemble averaging reduces overfitting and improves generalization.  \n",
        "- ROC-AUC is a robust metric when class imbalance exists.  \n",
        "\n",
        "---\n",
        "\n",
        "### Limitations\n",
        "- Less interpretable than single Decision Trees.  \n",
        "- May need many trees for stability.  \n",
        "- Tuning hyperparameters can be computationally expensive.\n"
      ],
      "metadata": {
        "id": "iyK4iO6acQz5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ Viva Questions\n",
        "\n",
        "1. What is the main idea behind Random Forest?  \n",
        "2. How does Random Forest prevent overfitting?  \n",
        "3. Why use ROC-AUC over Accuracy in medical problems?  \n",
        "4. What is the difference between bagging and boosting?  \n",
        "5. Which features had the most influence in your model?  \n",
        "6. How would you explain this model‚Äôs prediction to a clinician?  \n",
        "7. Why do we split data into training and testing sets?  \n",
        "8. What is the role of `max_depth` and `n_estimators` in Random Forest?\n"
      ],
      "metadata": {
        "id": "bhA54DOAcSav"
      }
    }
  ]
}