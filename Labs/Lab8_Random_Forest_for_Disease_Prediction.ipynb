{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "Lab8_Random_Forest_for_Disease_Prediction.ipynb",
      "authorship_tag": "ABX9TyPpkz7cRe9PGKTFVrgF4Fnc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anandchauhan21/Machine_Learning/blob/main/Labs/Lab8_Random_Forest_for_Disease_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ§ª Lab 8: Random Forest for Disease Prediction\n",
        "\n",
        "## ðŸŽ¯ Objective\n",
        "Train and evaluate a **Random Forest** model to predict the likelihood of a disease using patient demographic, clinical and lifestyle features.\n",
        "\n",
        "## âœ… Learning outcomes\n",
        "- Understand Random Forest basics (bagging, feature randomness)\n",
        "- Preprocess and balance clinical data\n",
        "- Train, evaluate, and tune a Random Forest classifier\n",
        "- Interpret feature importance and save the trained model\n"
      ],
      "metadata": {
        "id": "22nJfL0ceXKX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ§  Concept Recap â€” Random Forest\n",
        "\n",
        "- **Random Forest**: ensemble of decision trees trained on bootstrap samples and random feature subsets.\n",
        "- **Prediction (classification)**: majority vote across trees.\n",
        "- **Advantages**: robustness to noise, handles nonlinearity, provides feature importances.\n",
        "- **Limitations**: less interpretable, can be compute-heavy for many trees.\n",
        "- **Useful metrics for medical classification**: Precision, Recall, F1, ROC-AUC (esp. for imbalanced data).\n"
      ],
      "metadata": {
        "id": "KBonb8rleYkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell first\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (confusion_matrix, classification_report, roc_auc_score,\n",
        "                             roc_curve, accuracy_score, precision_score, recall_score, f1_score)\n",
        "from sklearn.utils import resample\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "sns.set(style=\"whitegrid\")\n",
        "np.random.seed(42)\n"
      ],
      "metadata": {
        "id": "0rqiP7pTeZ_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OPTION A: Synthetic dataset (quick start)\n",
        "def create_synthetic_patient_history(n=1000):\n",
        "    np.random.seed(42)\n",
        "    age = np.random.randint(18, 85, n)\n",
        "    bmi = np.round(np.random.normal(27, 4, n), 1)\n",
        "    systolic = np.round(110 + 0.5*age + 0.4*bmi + np.random.normal(0, 10, n), 1)\n",
        "    diastolic = np.round(70 + 0.2*age + 0.2*bmi + np.random.normal(0, 6, n), 1)\n",
        "    cholesterol = np.round(np.random.normal(200, 30, n), 1)\n",
        "    glucose = np.round(np.random.normal(100, 20, n), 1)\n",
        "    smoking = np.random.binomial(1, 0.25, n)\n",
        "    family_history = np.random.binomial(1, 0.2, n)\n",
        "    physical_activity = np.random.randint(0, 5, n)\n",
        "\n",
        "    # risk â†’ probability â†’ label\n",
        "    risk_score = (0.03*age + 0.06*bmi + 0.02*systolic + 0.015*cholesterol +\n",
        "                  0.5*smoking + 0.8*family_history - 0.2*physical_activity)\n",
        "    prob = 1 / (1 + np.exp(-0.08*(risk_score - 12)))\n",
        "    disease = np.random.binomial(1, prob)\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'Age': age, 'BMI': bmi, 'SystolicBP': systolic, 'DiastolicBP': diastolic,\n",
        "        'Cholesterol': cholesterol, 'Glucose': glucose,\n",
        "        'Smoking': smoking, 'FamilyHistory': family_history, 'PhysicalActivity': physical_activity,\n",
        "        'Disease': disease\n",
        "    })\n",
        "    return df\n",
        "\n",
        "# Create dataset\n",
        "df = create_synthetic_patient_history(1500)\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "Hmb6hb5uebtm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> OPTION B (use your CSV): replace the synthetic block with:\n",
        "```python\n",
        "# df = pd.read_csv('/path/to/patient_history.csv')\n",
        "# df = df[ ['Age','BMI','SystolicBP','DiastolicBP','Cholesterol','Glucose','Smoking','FamilyHistory','PhysicalActivity','Disease'] ]\n"
      ],
      "metadata": {
        "id": "duQI5_ekeg-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "---\n",
        "\n",
        "### ðŸ“Š Cell 5 â€” Quick EDA (Code)\n",
        "```python\n",
        "# Target balance\n",
        "print(\"Target distribution:\")\n",
        "print(df['Disease'].value_counts(), \"\\n\")\n",
        "\n",
        "# Summary statistics\n",
        "display(df.describe().T)\n",
        "\n",
        "# Correlation heatmap\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(df.corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
        "plt.title(\"Feature Correlation\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "v-0SS3SKeghT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['Age','BMI','SystolicBP','DiastolicBP','Cholesterol','Glucose',\n",
        "            'Smoking','FamilyHistory','PhysicalActivity']\n",
        "X = df[features].copy()\n",
        "y = df['Disease'].copy()\n",
        "\n",
        "# Train-test split (stratify to keep class ratio)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "print(\"Train class counts:\", y_train.value_counts().to_dict())\n",
        "print(\"Test class counts:\", y_test.value_counts().to_dict())\n",
        "\n",
        "# OPTIONAL: Upsample minority class in training (simple)\n",
        "train = pd.concat([X_train, y_train], axis=1)\n",
        "minority = train[train['Disease']==1]\n",
        "majority = train[train['Disease']==0]\n",
        "\n",
        "if len(minority) > 0 and len(minority) < 0.7 * len(majority):\n",
        "    minority_upsampled = resample(minority, replace=True, n_samples=len(majority), random_state=42)\n",
        "    train_bal = pd.concat([majority, minority_upsampled])\n",
        "    X_train = train_bal[features]\n",
        "    y_train = train_bal['Disease']\n",
        "    print(\"After upsampling (train):\", y_train.value_counts().to_dict())\n",
        "else:\n",
        "    print(\"No upsampling performed.\")\n",
        "\n",
        "# Scale numeric features (RF doesn't require it, but scaler useful for other models)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "WZYBsXxhekbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = rf.predict(X_test_scaled)\n",
        "y_proba = rf.predict_proba(X_test_scaled)[:,1]\n",
        "\n",
        "# Metrics\n",
        "print(\"Accuracy:\", round(accuracy_score(y_test, y_pred), 3))\n",
        "print(\"Precision:\", round(precision_score(y_test, y_pred), 3))\n",
        "print(\"Recall:\", round(recall_score(y_test, y_pred), 3))\n",
        "print(\"F1:\", round(f1_score(y_test, y_pred), 3))\n",
        "print(\"ROC AUC:\", round(roc_auc_score(y_test, y_proba), 3))\n",
        "\n",
        "print(\"\\nClassification report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "HHYs29yeelyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(4,3))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[0,1], yticklabels=[0,1])\n",
        "plt.xlabel(\"Predicted\"); plt.ylabel(\"Actual\"); plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc_score(y_test, y_proba):.3f}\")\n",
        "plt.plot([0,1],[0,1],'--', color='gray')\n",
        "plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fF3Y1VTDenCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feat_imp = pd.Series(rf.feature_importances_, index=features).sort_values(ascending=True)\n",
        "plt.figure(figsize=(7,5))\n",
        "feat_imp.plot(kind='barh', color='teal')\n",
        "plt.title(\"Feature Importances (Random Forest)\")\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.show()\n",
        "\n",
        "display(feat_imp.sort_values(ascending=False).round(3))\n"
      ],
      "metadata": {
        "id": "pjRTTwQ4epDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import randint as sp_randint\n",
        "\n",
        "param_dist = {\n",
        "    'n_estimators': sp_randint(50, 300),\n",
        "    'max_depth': sp_randint(3, 25),\n",
        "    'min_samples_split': sp_randint(2, 12),\n",
        "    'min_samples_leaf': sp_randint(1, 6),\n",
        "    'max_features': ['sqrt','log2', None, 0.5]\n",
        "}\n",
        "\n",
        "rsearch = RandomizedSearchCV(\n",
        "    estimator=RandomForestClassifier(random_state=42),\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=20, cv=3, scoring='roc_auc', random_state=42, n_jobs=-1\n",
        ")\n",
        "\n",
        "rsearch.fit(X_train_scaled, y_train)\n",
        "print(\"Best params:\", rsearch.best_params_)\n",
        "print(\"Best CV ROC AUC:\", round(rsearch.best_score_, 3))\n",
        "\n",
        "best_rf = rsearch.best_estimator_\n",
        "\n",
        "# Evaluate tuned model on test set\n",
        "y_pred_t = best_rf.predict(X_test_scaled)\n",
        "y_proba_t = best_rf.predict_proba(X_test_scaled)[:,1]\n",
        "print(\"\\nTuned model metrics on test set:\")\n",
        "print(\"ROC AUC:\", round(roc_auc_score(y_test, y_proba_t), 3))\n",
        "print(\"Accuracy:\", round(accuracy_score(y_test, y_pred_t), 3))\n",
        "print(\"F1:\", round(f1_score(y_test, y_pred_t), 3))\n"
      ],
      "metadata": {
        "id": "ZQd0-TBfeqP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(best_rf, \"lab8_rf_model.joblib\")\n",
        "joblib.dump(scaler, \"lab8_scaler.joblib\")\n",
        "print(\"Saved: lab8_rf_model.joblib, lab8_scaler.joblib\")\n"
      ],
      "metadata": {
        "id": "kcbkBR_TesBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example new patient\n",
        "new_patient = pd.DataFrame([{\n",
        "    'Age': 60, 'BMI': 30.2, 'SystolicBP': 145, 'DiastolicBP': 92,\n",
        "    'Cholesterol': 240, 'Glucose': 118, 'Smoking': 1, 'FamilyHistory': 1, 'PhysicalActivity': 1\n",
        "}])\n",
        "\n",
        "scaler = joblib.load(\"lab8_scaler.joblib\")\n",
        "model = joblib.load(\"lab8_rf_model.joblib\")\n",
        "Xn = scaler.transform(new_patient[features])\n",
        "prob = model.predict_proba(Xn)[0,1]\n",
        "pred = model.predict(Xn)[0]\n",
        "\n",
        "print(f\"Predicted disease probability: {prob:.3f}   Predicted label: {pred}\")\n"
      ],
      "metadata": {
        "id": "VWK8AY5-etIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.calibration import calibration_curve\n",
        "prob_pos = best_rf.predict_proba(X_test_scaled)[:,1]\n",
        "frac_pos, mean_pred = calibration_curve(y_test, prob_pos, n_bins=10)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(mean_pred, frac_pos, \"s-\", label=\"RandomForest\")\n",
        "plt.plot([0,1],[0,1],\"--\", color='gray')\n",
        "plt.xlabel(\"Mean predicted probability\"); plt.ylabel(\"Fraction of positives\")\n",
        "plt.title(\"Calibration plot\")\n",
        "plt.legend(); plt.show()\n"
      ],
      "metadata": {
        "id": "-pxNcsbFeuRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ” Recap â€” Lab 8: Random Forest for Disease Prediction\n",
        "\n",
        "**What we did**\n",
        "- Built/loaded patient dataset, explored features and the label.\n",
        "- Handled class imbalance (optional upsampling).\n",
        "- Trained a baseline Random Forest, evaluated with Precision, Recall, F1, ROC-AUC.\n",
        "- Tuned hyperparameters with RandomizedSearchCV and saved the best model.\n",
        "- Interpreted feature importances and predicted for a new patient.\n",
        "\n",
        "**Key reminders**\n",
        "- Use ROC-AUC and recall/precision when classes are imbalanced.\n",
        "- Feature importance helps clinical interpretability, but for per-prediction explanations consider SHAP/LIME.\n",
        "- Always validate model decisions with clinicians before deployment.\n"
      ],
      "metadata": {
        "id": "X7rI0yDueyYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âœ… Viva Questions\n",
        "\n",
        "1. Why is Random Forest suitable for disease prediction?  \n",
        "2. What does ROC-AUC represent and why is it useful for imbalanced datasets?  \n",
        "3. How does Random Forest reduce overfitting compared to a single decision tree?  \n",
        "4. When might you prefer calibration of predicted probabilities?  \n",
        "5. How would you explain the model prediction for a single patient to a clinician?\n"
      ],
      "metadata": {
        "id": "b73PNKRQezox"
      }
    }
  ]
}